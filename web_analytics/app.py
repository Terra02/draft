import os
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple
import altair as alt
import httpx
import pandas as pd
import streamlit as st

DEFAULT_API_URL = os.getenv("API_URL", "http://localhost:8000").rstrip("/")
DATA_LIMIT = 300

st.set_page_config(
    page_title="–ê–Ω–∞–ª–∏—Ç–∏–∫–∞",
    page_icon="üé¨",
    layout="wide",
    #initial_sidebar_state="expanded",
)

def _build_client(api_url: str) -> httpx.Client:
    return httpx.Client(base_url=api_url, timeout=10.0)

def _time_range_to_days(label: str) -> int:
    mapping = {
        "–í—Å–µ –≤—Ä–µ–º—è": 365,
    }
    return mapping.get(label, 30)

@st.cache_data(show_spinner=False, ttl=120)
def fetch_user_analytics(api_url: str, user_id: int, days: int) -> Optional[Dict[str, Any]]:
    try:
        with _build_client(api_url) as client:
            response = client.get(f"/api/v1/analytics/user/{user_id}", params={"days": days})
            response.raise_for_status()
            return response.json()
    except httpx.HTTPError as exc:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞–Ω–∞–ª–∏—Ç–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {exc}")
        return None
    
@st.cache_data(show_spinner=False, ttl=120)
def fetch_user_timeline(api_url: str, user_id: int, period: str = "monthly") -> List[Dict[str, Any]]:
    try:
        with _build_client(api_url) as client:
            response = client.get(
                f"/api/v1/analytics/user/{user_id}/timeline", params={"period": period}
            )
            response.raise_for_status()
            data = response.json()
            return data.get("data", []) if isinstance(data, dict) else []
    except httpx.HTTPError as exc:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É: {exc}")
        return []


@st.cache_data(show_spinner=False, ttl=120)
def fetch_view_history(api_url: str, user_id: int, limit: int = DATA_LIMIT) -> List[Dict[str, Any]]:
    records: List[Dict[str, Any]] = []
    page_size = min(limit, 100)
    try:
        with _build_client(api_url) as client:
            skip = 0
            while len(records) < limit:
                response = client.get(
                    f"/api/v1/view-history/user/{user_id}",
                    params={"skip": skip, "limit": min(page_size, limit - len(records))},
                )
                response.raise_for_status()
                chunk = response.json()
                if not chunk:
                    break
                records.extend(chunk)
                if len(chunk) < page_size:
                    break
                skip += page_size
    except httpx.HTTPError as exc:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: {exc}")
    return records


@st.cache_data(show_spinner=False, ttl=120)
def resolve_user_id(api_url: str, identifier: int) -> Optional[int]:
    try:
        with _build_client(api_url) as client:
            tg_response = client.get(f"/api/v1/users/telegram/{identifier}")
            if tg_response.status_code == 200:
                return tg_response.json().get("id")

            st.warning("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ Telegram ID.")
    except httpx.HTTPError as exc:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {exc}")
    return None


def build_dataframe(
    history: List[Dict[str, Any]], start_date: datetime, end_date: datetime
) -> pd.DataFrame:
    rows = []
    for record in history:
        watched_at = pd.to_datetime(record.get("watched_at"))
        if not pd.isna(watched_at) and watched_at.tzinfo is not None:
            watched_at = watched_at.tz_convert(None)
        if pd.isna(watched_at) or watched_at < start_date or watched_at > end_date:
            continue

        content = record.get("content") or {}
        content_type = content.get("content_type") or record.get("content_type")
        rows.append(
            {
                "title": content.get("title")
                or record.get("content_title")
                or "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è",
                "content_type": content_type,
                "user_rating": record.get("rating"),
                "watch_date": watched_at,
            }
        )

    df = pd.DataFrame(rows)
    if df.empty:
        return df

    df["watch_day"] = df["watch_date"].dt.date.astype(str)
    df["content_type_display"] = (
        df["content_type"].map({"movie": "–§–∏–ª—å–º", "series": "–°–µ—Ä–∏–∞–ª (–≠–ø–∏–∑–æ–¥)"}).fillna("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
    )
    return df

def format_duration(total_minutes: float) -> Tuple[str, str]:
    hours = round(total_minutes / 60, 1)
    days = round(hours / 24, 1)
    return f"{hours:,}", f"{days:,}"


def _filter_timeline(
    data: List[Dict[str, Any]], start: datetime, end: datetime
) -> pd.DataFrame:
    timeline_rows = []
    for row in data:
        period_raw = row.get("period") or row.get("month")
        if not period_raw:
            continue
        period_dt = pd.to_datetime(period_raw)
        if not pd.isna(period_dt) and period_dt.tzinfo is not None:
            period_dt = period_dt.tz_convert(None)
        if pd.isna(period_dt) or period_dt < start or period_dt > end:
            continue
        timeline_rows.append(
            {
                "watch_period": period_dt.strftime("%Y-%m-%d"),
                "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ": row.get("view_count", 0),
            }
        )
    return pd.DataFrame(timeline_rows)


# --- –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Ñ–∏–ª—å—Ç—Ä—ã ---
st.title("üé¨ –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ü—Ä–æ—Å–º–æ—Ç—Ä–æ–≤")

st.markdown(
    "–ó–¥–µ—Å—å –≤—ã –Ω–∞–π–¥–µ—Ç–µ –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–º —Ñ–∏–ª—å–º–∞–º –∏ —Å–µ—Ä–∏–∞–ª–∞–º,")

st.sidebar.header("–§–∏–ª—å—Ç—Ä—ã –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
api_url_input = st.sidebar.text_input(
    "API URL",
    value=DEFAULT_API_URL,
)
user_identifier = st.sidebar.number_input(
    "Telegram ID",
    min_value=1,
    value=1,
    step=1,
    help="–ú–æ–∂–Ω–æ –≤–≤–æ–¥–∏—Ç—å Telegram ID ‚Äî —Å–∏—Å—Ç–µ–º–∞ –Ω–∞–π–¥—ë—Ç –Ω—É–∂–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.",
)


days = _time_range_to_days("–í—Å–µ –≤—Ä–µ–º—è")
end_date = datetime.now()
start_date = end_date - timedelta(days=days)
api_url = api_url_input.rstrip("/")

resolved_user_id = resolve_user_id(api_url, user_identifier)
if resolved_user_id is None:
    st.stop()

analytics = fetch_user_analytics(api_url, resolved_user_id, days)
timeline = fetch_user_timeline(api_url, resolved_user_id, period="daily")
history_records = fetch_view_history(api_url, resolved_user_id, limit=DATA_LIMIT)
df = build_dataframe(history_records, start_date, end_date)

if df.empty and not analytics:
    st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã –∏–ª–∏ –Ω–∞–ª–∏—á–∏–µ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ.")
    st.stop()


# --- KPI (–ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏) ---
st.header("üìä –ö–ª—é—á–µ–≤—ã–µ –ú–µ—Ç—Ä–∏–∫–∏")

total_items = analytics.get("total_views") if analytics else len(df)
total_movies = analytics.get("movies_views") if analytics else int((df["content_type"] == "movie").sum())
total_series_episodes = (
    analytics.get("series_views") if analytics else int((df["content_type"] == "series").sum())
)
avg_rating = (
    analytics.get("average_rating") if analytics else round(df["user_rating"].dropna().mean(), 2)
)

col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric(label="–í—Å–µ–≥–æ –ü—Ä–æ—Å–º–æ—Ç—Ä–æ–≤", value=total_items)
    st.metric(label="–°—Ä–µ–¥–Ω–∏–π –†–µ–π—Ç–∏–Ω–≥", value=avg_rating)
with col2: 
    st.metric(label="–í—Å–µ–≥–æ –§–∏–ª—å–º–æ–≤", value=total_movies)
    st.metric(label="–í—Å–µ–≥–æ –≠–ø–∏–∑–æ–¥–æ–≤ –°–µ—Ä–∏–∞–ª–æ–≤", value=total_series_episodes)

st.divider()

# --- –ì—Ä–∞—Ñ–∏–∫–∏ –ê–Ω–∞–ª–∏—Ç–∏–∫–∏ ---

st.header("üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –î–∞–Ω–Ω—ã—Ö")
st.subheader("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ü—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –ø–æ –î–Ω—è–º")

daily_counts = _filter_timeline(timeline, start_date, end_date)
if daily_counts.empty and not df.empty:
    daily_counts = (
        df.groupby("watch_day").size().reset_index(name="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ").rename(columns={"watch_day": "watch_period"})
    )

if daily_counts.empty:
    st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ –ø–æ –¥–Ω—è–º.")
else:
    chart_daily = alt.Chart(daily_counts).mark_bar(color="#6366f1").encode(
        x=alt.X("watch_period", title="–î–∞—Ç–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞", sort="ascending"),
        y=alt.Y("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤"),
        tooltip=["watch_period", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"],
    ).properties(height=300)

    st.altair_chart(chart_daily.interactive(), use_container_width=True)

st.subheader("–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –§–∏–ª—å–º–æ–≤ –∏ –°–µ—Ä–∏–∞–ª–æ–≤")
type_counts = df.groupby("content_type_display").size().reset_index(name="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")

if type_counts.empty:
    st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–∏–∞–≥—Ä–∞–º–º—ã –ø–æ —Ç–∏–ø–∞–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞.")
else:
    chart_type = alt.Chart(type_counts).mark_arc(outerRadius=120).encode(
        theta=alt.Theta(field="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", type="quantitative"),color=alt.Color(field="content_type_display", title="–¢–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞"),
        tooltip=["content_type_display", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"],
    ).properties(height=350)
    

    st.altair_chart(chart_type, use_container_width=True)
    st.markdown("---")
    st.markdown(
        f"**–í—Å–µ–≥–æ —Ñ–∏–ª—å–º–æ–≤:** {total_movies} | **–í—Å–µ–≥–æ —ç–ø–∏–∑–æ–¥–æ–≤:** {total_series_episodes}"
    )

st.header("üìñ –ü–æ—Å–ª–µ–¥–Ω–∏–µ –ü—Ä–æ—Å–º–æ—Ç—Ä—ã")

if df.empty:
    st.info("–ù–µ—Ç –Ω–µ–¥–∞–≤–Ω–∏—Ö –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ.")
else:
    recent_views = df.sort_values(by="watch_date", ascending=False)[
        ["title", "content_type_display", "user_rating", "watch_date"]
    ].head(10)
    recent_views.columns = [
        "–ù–∞–∑–≤–∞–Ω–∏–µ",
        "–¢–∏–ø",
        "–†–µ–π—Ç–∏–Ω–≥",
        "–î–∞—Ç–∞ –ü—Ä–æ—Å–º–æ—Ç—Ä–∞",
    ]
    st.dataframe(recent_views, use_container_width=True)

st.divider()
